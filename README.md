# NewsAI: RAG Adaptatif pour la Synth√®se d'Actualit√©s IA

Ce projet est une plateforme sp√©cialis√©e dans la veille technologique sur l'intelligence artificielle. Bas√© sur une architecture RAG (Retrieval-Augmented Generation) avanc√©e, il utilise LangGraph pour cr√©er un flux de travail dynamique capable de synth√©tiser des actualit√©s sur l'IA √† partir de deux sources distinctes : des documents PDF fournis par l'utilisateur ou une recherche en temps r√©el sur le web.

![Intelligence Artificielle](https://img.shields.io/badge/AI-Intelligence%20Artificielle-blue)
![Python](https://img.shields.io/badge/python-v3.10+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?logo=streamlit&logoColor=white)
![LangGraph](https://img.shields.io/badge/LangGraph-ü¶ú-green)

## üöÄ Fonctionnalit√©s Cl√©s

- **Double Source d'Information** : Obtenez des r√©sum√©s d'actualit√©s sur l'IA soit en t√©l√©versant un article (fichier .pdf ou .txt), soit en posant directement une question pour lancer une recherche sur le web.

- **Synth√®se Automatique** : Le c≈ìur du syst√®me est sa capacit√© √† lire le contenu (qu'il provienne d'un fichier ou du web) et √† en g√©n√©rer un r√©sum√© concis et pertinent.

- **Recherche Web en Temps R√©el** : Si vous ne fournissez pas de document, le syst√®me utilise l'API Tavily pour rechercher les derni√®res informations sur le sujet de l'IA qui vous int√©resse.

- **Auto-Correction Intelligente** : Gr√¢ce √† un m√©canisme d'auto-r√©flexion, le syst√®me √©value la pertinence des informations trouv√©es et la qualit√© de ses propres r√©sum√©s pour garantir une r√©ponse fiable et pr√©cise.

- **Interface Utilisateur Intuitive** : L'application Streamlit permet une interaction simple : t√©l√©versez un fichier ou posez une question pour recevoir un r√©sum√© clair et direct.

## üèõÔ∏è Architecture

L'architecture reste modulaire et robuste, mais elle est d√©sormais optimis√©e pour la synth√®se d'actualit√©s.

### Interface Utilisateur (`streamlit_app.py`)
- Permet √† l'utilisateur de choisir son mode d'interaction : t√©l√©verser un document ou poser une question
- Traite les fichiers t√©l√©vers√©s ou transmet la question au moteur du graphe
- Affiche le r√©sum√© final de mani√®re conversationnelle

### Moteur du Graphe (`graph.py`)
- Orchestre le flux de travail avec LangGraph
- La logique principale est de diriger la requ√™te vers le traitement de document ou la recherche web

### N≈ìuds et Cha√Ænes LLM
Les composants internes (r√©cup√©ration, √©valuation, r√©√©criture de requ√™te) sont maintenant appliqu√©s soit au contenu du document, soit aux r√©sultats de la recherche web pour produire le meilleur r√©sum√© possible.

## ü§ñ Mod√®les et Composants Techniques

Le projet s'appuie sur une s√©lection de mod√®les et de technologies de pointe pour assurer sa performance.

- **Fournisseur de LLM** : Groq
- **Mod√®le utilis√©** : `gemma2-9b-it` - Particuli√®rement efficace pour les t√¢ches de synth√®se, de g√©n√©ration et de compr√©hension de texte
- **Mod√®le d'Embedding** : Hugging Face (`sentence-transformers/all-MiniLM-L6-v2`) - Utilis√© pour vectoriser le contenu des documents t√©l√©vers√©s
- **Base de Donn√©es Vectorielle** : ChromaDB - Stocke les vecteurs des documents PDF pour permettre au syst√®me de "lire" et de comprendre le contenu
- **API de Recherche Web** : Tavily AI - Le moteur de recherche pour trouver les actualit√©s les plus r√©centes sur l'IA

## ‚öôÔ∏è Flux de Travail d'une Requ√™te

1. **Entr√©e** : L'utilisateur arrive sur l'application Streamlit

2. **Choix de l'Action** :
   - **Cas 1 (Fichier fourni)** : L'utilisateur t√©l√©verse un document. Le syst√®me le d√©coupe, le vectorise et le stocke. Le flux RAG interne est ensuite utilis√© pour extraire et r√©sumer les points cl√©s du document.
   - **Cas 2 (Question pos√©e)** : L'utilisateur pose une question dans le champ de saisie. Le syst√®me active le n≈ìud de recherche web (WEBSEARCH) pour collecter des articles et des informations pertinents.

3. **G√©n√©ration du R√©sum√©** (`generate`) : Que les informations proviennent du document ou du web, le LLM gemma2-9b-it est charg√© de synth√©tiser les informations en un r√©sum√© clair et concis.

4. **Auto-R√©flexion et Validation** : Le r√©sum√© est v√©rifi√© pour s'assurer qu'il est factuel (bas√© sur la source) et qu'il r√©pond bien √† la demande implicite de l'utilisateur.

5. **Affichage** : Le r√©sum√© final est pr√©sent√© √† l'utilisateur dans l'interface de chat.

## üõ†Ô∏è Installation et Utilisation

### Pr√©requis
- Python 3.10+
- Un gestionnaire de paquets comme pip

### 1. Cloner le D√©p√¥t
```bash
git clone <URL_DU_DEPOT>
cd <NOM_DU_DEPOT>
```

### 2. Installer les D√©pendances
```bash
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Configurer les Variables d'Environnement
Cr√©ez un fichier `.env` avec vos cl√©s d'API :
```env
# .env
GROQ_API_KEY="gsk_..."
TAVILY_API_KEY="tvly-..."
```

### 4. Lancer l'Application
```bash
streamlit run streamlit_app.py
```

Ouvrez votre navigateur √† `http://localhost:8501`. Vous pouvez maintenant t√©l√©verser un document ou poser une question pour obtenir un r√©sum√© des actualit√©s sur l'IA.

## üìÅ Structure du Projet
```
NewsAI/
‚îú‚îÄ‚îÄ streamlit_app.py    # Interface utilisateur Streamlit
‚îú‚îÄ‚îÄ graph.py           # Moteur du graphe LangGraph
‚îú‚îÄ‚îÄ requirements.txt   # D√©pendances Python
‚îú‚îÄ‚îÄ .env              # Variables d'environnement (√† cr√©er)
‚îî‚îÄ‚îÄ README.md         # Ce fichier
```

## ü§ù Contribution

Les contributions sont les bienvenues ! N'h√©sitez pas √† ouvrir une issue ou √† soumettre une pull request.

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de d√©tails.

---

‚≠ê **N'oubliez pas de donner une √©toile au projet si vous l'avez trouv√© utile !**
