# graph.py (Version Finalis√©e & Nettoy√©e)

import time
import traceback
from typing import Dict, Any, Optional
from dotenv import load_dotenv
from langgraph.graph import END, StateGraph
from langgraph.checkpoint.memory import MemorySaver

# --- Import des composants du graphe ---
from chains.answer_grader import answer_grader
from chains.retriever_grader import retrieval_grader
from chains.router_query import question_router
from chains.hallucination_grader import hallucination_grader
from nodes.generate import generate
from nodes.web_search import web_search
from nodes.query_rewrite import query_rewrite
from Node_constant import RETRIEVE, GRADE_DOCUMENTS, GENERATE, WEBSEARCH, QUERY_REWRITE
from state import GraphState

# --- Import de l'initialiseur du retriever par d√©faut ---
from ingestion.ingestion import initialize_default_retriever

load_dotenv()


class AdaptiveRAGSystem:
    """Syst√®me RAG modulaire, robuste et centralis√©."""

    def __init__(self):
        """Initialise le syst√®me RAG avec un retriever par d√©faut."""
        self.workflow = StateGraph(GraphState)

        # --- Initialisation du retriever par d√©faut ---
        try:
            self.default_retriever = initialize_default_retriever()
        except Exception as e:
            print(f"‚ùå ERREUR CRITIQUE: Impossible d'initialiser le retriever par d√©faut: {e}")
            self.default_retriever = None

        self.current_retriever = self.default_retriever

        # --- Construction du graphe ---
        self._setup_workflow()

        # --- Compilation du graphe ---
        memory = MemorySaver()
        self.app = self.workflow.compile(checkpointer=memory)
        print("‚úÖ Graphe LangGraph compil√© avec succ√®s.")

    # --- N≈ìud : r√©cup√©ration des documents ---
    def _retrieve_documents(self, state: GraphState) -> Dict[str, Any]:
        print("---N≈íUD: R√âCUP√âRATION DE DOCUMENTS---")
        question = state["question"]

        if self.current_retriever is None:
            print("‚ö†Ô∏è Aucun retriever disponible. Retourne une liste vide.")
            return {"documents": []}

        try:
            print(f"üîé Utilisation du retriever: {type(self.current_retriever)}")
            documents = self.current_retriever.invoke(question)
            print(f"‚úÖ {len(documents)} document(s) r√©cup√©r√©(s).")
            return {"documents": documents}
        except Exception as e:
            print(f"‚ùå Erreur lors de la r√©cup√©ration: {e}")
            return {"documents": []}

    # --- N≈ìud : √©valuation de pertinence des documents ---
    def _grade_documents(self, state: GraphState) -> Dict[str, Any]:
        print("---N≈íUD: √âVALUATION PERTINENCE DOCUMENTS---")
        question = state["question"]
        documents = state["documents"]

        if not documents:
            return {"documents": []}

        filtered_docs = []
        for d in documents:
            try:
                doc_text = getattr(d, "page_content", str(d))
                score = retrieval_grader.invoke({"question": question, "document": doc_text})
                if getattr(score, "binary_score", False):
                    print("‚úÖ Document pertinent.")
                    filtered_docs.append(d)
                else:
                    print("‚õî Document non pertinent.")
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur d'√©valuation ‚Üí inclusion par d√©faut: {e}")
                filtered_docs.append(d)

        return {"documents": filtered_docs}

    # --- N≈ìud : routage de la question ---
    def _route_question(self, state: GraphState) -> str:
        print("---N≈íUD: ROUTAGE QUESTION---")
        print("‚û°Ô∏è Toujours router vers RETRIEVE (retriever dispo).")
        return RETRIEVE

    # --- N≈ìud : d√©cision apr√®s r√©cup√©ration ---
    def _decide_to_generate(self, state: GraphState) -> str:
        print("---N≈íUD: D√âCISION POST-R√âCUP√âRATION---")
        if state["documents"]:
            print("‚úÖ Documents trouv√©s ‚Üí G√©n√©ration.")
            return GENERATE
        if state["query_rewrite_count"] < 1:
            print("‚õî Aucun doc pertinent ‚Üí R√©√©criture de la question.")
            return QUERY_REWRITE
        print("‚õî √âchec apr√®s r√©√©criture ‚Üí Recherche Web.")
        return WEBSEARCH

    # --- N≈ìud : √©valuation de la g√©n√©ration ---
    def _grade_generation(self, state: GraphState) -> str:
        print("---N≈íUD: √âVALUATION G√âN√âRATION---")
        question = state["question"]
        documents = state["documents"]
        generation = state["generation"]

        if not generation:
            print("‚õî Generation vide. Fin.")
            return END

        # Cas Web Search ‚Üí pas de check hallucination
        if not documents:
            print("‚ö†Ô∏è R√©ponse issue du web ‚Üí V√©rification utilit√©.")
            answer_score = answer_grader.invoke({"question": question, "generation": generation})
            if getattr(answer_score, "binary_score", False):
                print("‚úÖ R√©ponse Web UTILE.")
            else:
                print("‚õî R√©ponse Web NON UTILE.")
            return END

        # Pr√©paration du contexte
        MAX_CONTEXT_CHARS = 15000
        docs_texts = [getattr(d, "page_content", str(d)) for d in documents]
        full_context = "\n\n---\n\n".join(docs_texts)

        if len(full_context) > MAX_CONTEXT_CHARS:
            print(f"‚ö†Ô∏è Contexte trop long ({len(full_context)}). Troncature.")
            full_context = full_context[:MAX_CONTEXT_CHARS]

        documents_text = str(full_context)

        # V√©rification hallucinations
        try:
            hallucination_score = hallucination_grader.invoke({
                "documents": documents_text[:5000],
                "generation": generation[:2000]
            })
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur hallucination_grader: {e}")
            return END

        if not getattr(hallucination_score, "binary_score", False):
            print("‚õî HALLUCINATION d√©tect√©e ‚Üí Retry si possible.")
            if state["generation_count"] < 1:
                return GENERATE
            print("‚õî √âchec apr√®s retry. Fin.")
            return END

        # V√©rification pertinence
        print("‚úÖ G√©n√©ration ancr√©e. V√©rification pertinence.")
        answer_score = answer_grader.invoke({"question": question, "generation": generation})
        if getattr(answer_score, "binary_score", False):
            print("‚úÖ R√©ponse PERTINENTE & ANCR√âE.")
        else:
            print("‚õî R√©ponse NON pertinente (mais ancr√©e).")
        return END

    # --- Construction du graphe ---
    def _setup_workflow(self):
        self.workflow.set_entry_point(RETRIEVE)

        self.workflow.add_node(RETRIEVE, self._retrieve_documents)
        self.workflow.add_node(GRADE_DOCUMENTS, self._grade_documents)
        self.workflow.add_node(QUERY_REWRITE, query_rewrite)
        self.workflow.add_node(WEBSEARCH, web_search)
        self.workflow.add_node(GENERATE, generate)

        # Edges
        self.workflow.add_edge(RETRIEVE, GRADE_DOCUMENTS)
        self.workflow.add_edge(QUERY_REWRITE, RETRIEVE)
        self.workflow.add_edge(WEBSEARCH, GENERATE)

        self.workflow.add_conditional_edges(
            GRADE_DOCUMENTS,
            self._decide_to_generate,
            {GENERATE: GENERATE, QUERY_REWRITE: QUERY_REWRITE, WEBSEARCH: WEBSEARCH},
        )
        self.workflow.add_conditional_edges(
            GENERATE,
            self._grade_generation,
            {GENERATE: GENERATE, END: END},
        )

    # --- API publique ---
    def ask_question(self, question: str, retriever: Optional[Any] = None, config: Optional[Dict] = None) -> Dict[str, Any]:
        if not self.app:
            return {"success": False, "answer": "Erreur: Graphe RAG non compil√©."}

        # Choix du retriever (custom ou d√©faut)
        self.current_retriever = retriever if retriever is not None else self.default_retriever
        if self.current_retriever is None:
            return {"success": False, "answer": "Erreur: Aucun retriever disponible."}

        initial_state = {"question": question, "query_rewrite_count": 0, "generation_count": 0}
        print(f"--- Lancement graphe pour question: '{question}' ---")
        start_time = time.time()

        final_state = None
        try:
            for event in self.app.stream(initial_state, config=config, stream_mode="values"):
                final_state = event

            end_time = time.time()
            answer = final_state.get("generation", "Aucune r√©ponse g√©n√©r√©e.")
            docs_used = final_state.get("documents", [])

            return {
                "success": True,
                "answer": answer,
                "processing_time": round(end_time - start_time, 2),
                "documents_used": len(docs_used),
                "query_rewrites": final_state.get("query_rewrite_count", 0),
                "documents": docs_used,
            }
        except Exception as e:
            end_time = time.time()
            print(f"--- ERREUR EXECUTION GRAPHE: {e} ---")
            traceback.print_exc()
            return {
                "success": False,
                "answer": f"Erreur: {e}",
                "processing_time": round(end_time - start_time, 2),
            }


# --- Instance unique pour l'application ---
rag_system = AdaptiveRAGSystem()
