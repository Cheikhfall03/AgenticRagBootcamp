# graph.py (Version Corrig√©e)
import time
import traceback
from typing import Dict, Any, Optional
from dotenv import load_dotenv
from langgraph.graph import END, StateGraph
from langgraph.checkpoint.memory import MemorySaver

# --- Import des composants du graphe ---
from chains.answer_grader import answer_grader
from chains.retriever_grader import retrieval_grader
from chains.router_query import question_router
from chains.hallucination_grader import hallucination_grader
from nodes.generate import generate
from nodes.web_search import web_search
from nodes.query_rewrite import query_rewrite
from Node_constant import RETRIEVE, GRADE_DOCUMENTS, GENERATE, WEBSEARCH, QUERY_REWRITE
from state import GraphState

# --- Import de l'initialiseur du retriever par d√©faut ---
from ingestion import initialize_default_retriever

load_dotenv()

class AdaptiveRAGSystem:
    """Syst√®me RAG modulaire, robuste et centralis√©."""
    
    def __init__(self):
        """Initialise le syst√®me RAG avec un retriever par d√©faut."""
        self.workflow = StateGraph(GraphState)
        
        # --- Initialisation du retriever par d√©faut ---
        try:
            self.default_retriever = initialize_default_retriever()
        except Exception as e:
            print(f"‚ùå ERREUR CRITIQUE: Impossible d'initialiser le retriever par d√©faut: {e}")
            self.default_retriever = None
            
        self.current_retriever = self.default_retriever
        
        # --- Construction du graphe ---
        self._setup_workflow()
        
        # --- Compilation du graphe ---
        memory = MemorySaver()
        self.app = self.workflow.compile(checkpointer=memory)
        print("‚úÖ Graphe LangGraph compil√© avec succ√®s.")

    def _retrieve_documents(self, state: GraphState) -> Dict[str, Any]:
        """
        R√©cup√®re les documents en utilisant le retriever actuellement actif (soit par d√©faut, soit personnalis√©).
        Ce n≈ìud est maintenant interne √† la classe et fiable.
        """
        print("---N≈íUD: R√âCUP√âRATION DE DOCUMENTS---")
        question = state["question"]
        
        if self.current_retriever is None:
            print("‚ö†Ô∏è Aucun retriever n'est disponible. Retourne une liste vide.")
            return {"documents": []}
            
        try:
            print(f"üîé Utilisation du retriever: {type(self.current_retriever)}")
            documents = self.current_retriever.invoke(question)
            print(f"‚úÖ {len(documents)} document(s) r√©cup√©r√©(s).")
            return {"documents": documents}
        except Exception as e:
            print(f"‚ùå Erreur lors de la r√©cup√©ration de documents: {e}")
            return {"documents": []}

    # ... (les autres fonctions du graphe comme _grade_documents, etc. restent les m√™mes) ...

    def _grade_documents(self, state: GraphState) -> Dict[str, Any]:
        print("---N≈íUD: √âVALUATION DE LA PERTINENCE DES DOCUMENTS---")
        question = state["question"]
        documents = state["documents"]
        
        if not documents:
            return {"documents": []}
        
        filtered_docs = []
        for d in documents:
            try:
                doc_text = getattr(d, "page_content", str(d))
                score = retrieval_grader.invoke({"question": question, "document": doc_text})
                if getattr(score, "binary_score", False):
                    print("‚úÖ Document pertinent.")
                    filtered_docs.append(d)
                else:
                    print("‚õî Document non pertinent.")
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur d'√©valuation, inclusion par d√©faut: {e}")
                filtered_docs.append(d) # En cas d'erreur, on garde le doc par s√©curit√©
                
        return {"documents": filtered_docs}
    
    def _route_question(self, state: GraphState) -> str:
        """
        Route toujours vers la r√©cup√©ration de documents, car nous avons toujours un retriever.
        """
        print("---N≈íUD: ROUTAGE DE LA QUESTION---")
        print("‚û°Ô∏è Toujours router vers RETRIEVE car un retriever (d√©faut ou custom) est toujours disponible.")
        return RETRIEVE

    def _decide_to_generate(self, state: GraphState) -> str:
        """
        D√©cide s'il faut g√©n√©rer une r√©ponse, r√©√©crire la question, ou passer √† la recherche web.
        """
        print("---N≈íUD: D√âCISION POST-R√âCUP√âRATION---")
        if state["documents"]:
            print("‚úÖ Documents pertinents trouv√©s. Passage √† la g√©n√©ration.")
            return GENERATE
        else:
            if state["query_rewrite_count"] < 1: # On autorise 1 r√©√©criture
                 print("‚õî Aucun document pertinent. Tentative de r√©√©criture de la question.")
                 return QUERY_REWRITE
            else:
                 print("‚õî √âchec apr√®s r√©√©criture. Passage √† la recherche web comme dernier recours.")
                 return WEBSEARCH
    
    def _grade_generation(self, state: GraphState) -> str:
        """√âvalue la g√©n√©ration pour les hallucinations et la pertinence."""
        print("---N≈íUD: √âVALUATION DE LA G√âN√âRATION---")
        question = state["question"]
        documents = state["documents"]
        generation = state["generation"]
        
        if not documents: # Si on vient du web search, on ne peut pas v√©rifier les hallucinations
            print("‚ö†Ô∏è Impossible de v√©rifier les hallucinations (source web). On v√©rifie la pertinence de la r√©ponse.")
            score = answer_grader.invoke({"question": question, "generation": generation})
            if getattr(score, "binary_score", False):
                print("‚úÖ R√©ponse jug√©e utile.")
                return END
            else:
                print("‚õî R√©ponse jug√©e non utile. Fin.")
                return END # On pourrait boucler, mais finissons ici pour √©viter les boucles infinies.

        docs_texts = [getattr(d, "page_content", str(d)) for d in documents]
        hallucination_score = hallucination_grader.invoke({"documents": docs_texts, "generation": generation})
        
        if not getattr(hallucination_score, "binary_score", False):
            print("‚õî HALLUCINATION D√âTECT√âE ! Tentative de re-g√©n√©ration.")
            if state["generation_count"] < 1:
                return GENERATE # On re-g√©n√®re une fois
            else:
                print("‚õî √âchec de la re-g√©n√©ration. Fin.")
                return END
                
        print("‚úÖ Aucune hallucination d√©tect√©e.")
        answer_score = answer_grader.invoke({"question": question, "generation": generation})
        if getattr(answer_score, "binary_score", False):
            print("‚úÖ R√©ponse jug√©e utile.")
            return END
        else:
            print("‚õî R√©ponse jug√©e non utile, mais non hallucinatoire. Fin.")
            return END

    def _setup_workflow(self):
        """Construit et connecte les n≈ìuds du graphe LangGraph."""
        self.workflow.set_entry_point(RETRIEVE) # <--- POINT D'ENTR√âE SIMPLIFI√â
        
        self.workflow.add_node(RETRIEVE, self._retrieve_documents)
        self.workflow.add_node(GRADE_DOCUMENTS, self._grade_documents)
        self.workflow.add_node(QUERY_REWRITE, query_rewrite)
        self.workflow.add_node(WEBSEARCH, web_search)
        self.workflow.add_node(GENERATE, generate)
        
        # --- D√©finition des chemins (edges) ---
        self.workflow.add_edge(RETRIEVE, GRADE_DOCUMENTS)
        self.workflow.add_edge(QUERY_REWRITE, RETRIEVE)
        self.workflow.add_edge(WEBSEARCH, GENERATE)
        
        self.workflow.add_conditional_edges(
            GRADE_DOCUMENTS,
            self._decide_to_generate,
            {
                GENERATE: GENERATE,
                QUERY_REWRITE: QUERY_REWRITE,
                WEBSEARCH: WEBSEARCH
            }
        )
        self.workflow.add_conditional_edges(
            GENERATE,
            self._grade_generation,
            {
                GENERATE: GENERATE,
                END: END
            }
        )
        
    def ask_question(self, question: str, retriever: Optional[Any] = None, config: Optional[Dict] = None) -> Dict[str, Any]:
        """
        Point d'entr√©e principal pour poser une question au syst√®me.
        G√®re intelligemment le retriever √† utiliser.
        """
        if not self.app:
            return {"success": False, "answer": "Erreur: Le syst√®me RAG n'est pas compil√©."}
            
        # --- LOGIQUE CENTRALE CORRIG√âE ---
        # Si un retriever est fourni (fichiers upload√©s), on l'utilise.
        # Sinon, on utilise le retriever par d√©faut initialis√© au d√©marrage.
        self.current_retriever = retriever if retriever is not None else self.default_retriever
        
        if self.current_retriever is None:
             return {"success": False, "answer": "Erreur: Aucun retriever n'est disponible (ni par d√©faut, ni personnalis√©)."}

        initial_state = {"question": question, "query_rewrite_count": 0, "generation_count": 0}
        
        print(f"--- Lancement du graphe pour la question: '{question}' ---")
        start_time = time.time()
        
        final_state = None
        try:
            for event in self.app.stream(initial_state, config=config, stream_mode="values"):
                final_state = event
            
            end_time = time.time()
            
            answer = final_state.get("generation", "Aucune r√©ponse n'a pu √™tre g√©n√©r√©e.")
            docs_used = final_state.get("documents", [])
            
            return {
                "success": True,
                "answer": answer,
                "processing_time": round(end_time - start_time, 2),
                "documents_used": len(docs_used),
                "query_rewrites": final_state.get("query_rewrite_count", 0),
                "documents": docs_used,
            }
        except Exception as e:
            end_time = time.time()
            print(f"--- ERREUR D'EX√âCUTION DU GRAPHE: {e} ---")
            traceback.print_exc()
            return {
                "success": False,
                "answer": f"Une erreur est survenue: {e}",
                "processing_time": round(end_time - start_time, 2),
            }

# --- Instance unique (Singleton) pour l'application ---
rag_system = AdaptiveRAGSystem()
